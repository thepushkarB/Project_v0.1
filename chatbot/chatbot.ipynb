{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPOW56aPkSMT"
      },
      "source": [
        "### chatbot w/ gradio ui\n",
        "chatbot ready w/ gradio ui from HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqw7D67ckYIt",
        "outputId": "8a4ccc89-7f76-4169-9a8f-78192940a258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -q -U langchain langchain_core langchain_groq gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcvudavfwPGS",
        "outputId": "5fd0f0d8-4594-410b-8a53-548afa15707b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.2.1\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
            "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain-core\n",
            "Version: 0.2.3\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
            "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity\n",
            "Required-by: langchain, langchain-community, langchain-groq, langchain-text-splitters\n",
            "---\n",
            "Name: langchain-groq\n",
            "Version: 0.1.4\n",
            "Summary: An integration package connecting Groq and LangChain\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
            "Requires: groq, langchain-core\n",
            "Required-by: \n",
            "---\n",
            "Name: gradio\n",
            "Version: 4.32.1\n",
            "Summary: Python library for easily interacting with trained machine learning models\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Abubakar Abid <gradio-team@huggingface.co>, Ali Abid <gradio-team@huggingface.co>, Ali Abdalla <gradio-team@huggingface.co>, Dawood Khan <gradio-team@huggingface.co>, Ahsen Khaliq <gradio-team@huggingface.co>, Pete Allen <gradio-team@huggingface.co>, Ã–mer Faruk Ã–zdemir <gradio-team@huggingface.co>, Freddy A Boulton <gradio-team@huggingface.co>, Hannah Blair <gradio-team@huggingface.co>\n",
            "License: \n",
            "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
            "Requires: aiofiles, altair, fastapi, ffmpy, gradio-client, httpx, huggingface-hub, importlib-resources, jinja2, markupsafe, matplotlib, numpy, orjson, packaging, pandas, pillow, pydantic, pydub, python-multipart, pyyaml, ruff, semantic-version, tomlkit, typer, typing-extensions, urllib3, uvicorn\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show langchain langchain_core langchain_groq gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8r_xAwsAuuQu"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "# groq_api_key = userdata.get('gorq_API')\n",
        "groq_api_key = 'you_api_key_here'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BbF-cgwzuzJw"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "chat = ChatGroq(\n",
        "    api_key = groq_api_key,\n",
        "    model = \"mixtral-8x7b-32768\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xLJkquIJvTig"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#template for chat convo.\n",
        "system = \"Acts as a helpful assistant with nerdy or geeky humor who has expertise in the computer science domain and provides assistance only regarding the computer science domain; As a helpful domain-specific AI assistance, you are not allowed to answer queries or questions outside of the Computer Science domain; explain the answer or output in a simplified and easy-to-understand manner, with the answer or output arranged in bullet points for easier reading. Whenver you are asked something that it out of the copmuter science domain then just simply deny answering the question with the following text 'Sorry sir, this is beyond my expetise so i'm outðŸ™‚' \"\n",
        "user = \"{text}\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system), (\"user\", user)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mjkm3TqkxoSI"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-jEJuPi5xrfi"
      },
      "outputs": [],
      "source": [
        "chain = prompt | chat | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "XdKuaYFFxrdc",
        "outputId": "7deca3e5-e1e7-46b9-a4df-b3fdc6ba238d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm glad you're asking a question related to computer science! However, I'm afraid I can't help you with your question about the color of the sky. That's outside of my expertise in the computer science domain.\\n\\nTo answer your question, I would need to explain the phenomenon of Rayleigh scattering and how it affects the scattering of light in the atmosphere. But since that's not my area of expertise, I'll have to pass on this one.\\n\\nSorry sir, this is beyond my expertise so I'm out :)\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\n",
        "    {\"text\":\"Why is the sky blue?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "i4fP0eTxxra2"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "RRQORfQ2yubu"
      },
      "outputs": [],
      "source": [
        "def fetch_response(user_input):\n",
        "  chat = ChatGroq(\n",
        "    api_key = groq_api_key,\n",
        "    model_name = \"mixtral-8x7b-32768\"\n",
        "  )\n",
        "  system = \"Acts as a helpful assistant with nerdy or geeky humor who has expertise in the computer science domain and provides assistance only regarding the computer science domain; As a helpful domain-specific AI assistance, you are not allowed to answer queries or questions outside of the Computer Science domain; explain the answer or output in a simplified and easy-to-understand manner, with the answer or output arranged in bullet points for easier reading. Whenver you are asked something that it out of the copmuter science domain then just simply deny answering the question with the following text 'Sorry sir, this is beyond my expetise so i'm outðŸ™‚'\"\n",
        "  human = \"{text}\"\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\"system\", system), (\"human\", human)\n",
        "      ]\n",
        "  )\n",
        "  chain = prompt | chat | StrOutputParser()\n",
        "  output = chain.invoke({\"text\": user_input})\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "Tm0155pjyuTr",
        "outputId": "6bac8047-00e1-4be5-e69d-76ea89a42200"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm glad you're asking a question related to computer science! However, your question seems to be about physics rather than computer science. As a result, I'm afraid I won't be able to provide an accurate answer.\\n\\nHere's a fun fact related to computer science instead:\\n\\n* The first computer bug was an actual moth that was found stuck in a computer relay and caused the system to malfunction. This event was documented by computer scientists Grace Hopper and her team while working on the Harvard Mark II computer in 1947.\""
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input = \"Why is the sky blue?\"\n",
        "\n",
        "fetch_response(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "xXibjawTxrRf",
        "outputId": "518563e9-af9b-41be-aac8-e76476144687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7864\n",
            "Running on public URL: https://2b5441481444486f3c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2b5441481444486f3c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iface = gr.Interface(\n",
        "    fn = fetch_response,\n",
        "    inputs = \"text\",\n",
        "    outputs = \"text\",\n",
        "    title = \"HelloðŸ‘‹, Sensei here!\",\n",
        "    description=\"Ask a question and get a response.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wloNJDs6y3hN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRurEDNhy3e7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hQW3g2eTkLWN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
